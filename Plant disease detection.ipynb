{"cells":[{"metadata":{"_uuid":"1020827e241ac87ffdf8e0f8762a6885bdc28fbc"},"cell_type":"markdown","source":"Import neccessary packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pickle\nimport cv2\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n#from keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.models import Model\nimport os\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.applications.vgg16 import VGG16\n#from keras.applications import MobileNet,InceptionResNetV2\n#from keras.applications.InceptionResNetV2 import preprocess_input\n#from keras.applications.xception import Xception, preprocess_input\n# load the model\nfrom keras.applications.vgg16 import preprocess_input","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"7c3354a78e21a1a62ad0c4689d0ab3238fb760d4"},"cell_type":"code","source":"EPOCHS = 25\nINIT_LR = 1e-3\nBS = 32\ndefault_image_size = tuple((256, 256))\nimage_size = 0\ndirectory_root = '../input/plantvillage/'\nwidth=256\nheight=256\ndepth=3\nbatch_size=64\nnb_epochs=50\nprint(os.listdir(\"../input\"))","execution_count":2,"outputs":[{"output_type":"stream","text":"['plantdisease']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfile_count = sum(len(files) for _, _, files in os.walk('../input/plantdisease/'))\nprint(file_count)\n\ntotal_files = 0\ntotal_dirs = 0\nfor root, dirs, files in os.walk('../input/plantdisease/'):\n    total_files += len(files)\n    total_dirs += len(dirs)\nprint(total_files)\nprint(total_dirs)\n\nfor r, d, f in os.walk('../input/plantdisease/'):\n    for file in f:\n        if '.txt' in file:\n            files.append(os.path.join(r, file))\n\nfor f in files:\n    print(f)\n\n\nprint([x[0] for x in os.walk('../input/plantdisease/')])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24d42b87fad54a9556f78357ce673cc5152468c1"},"cell_type":"markdown","source":"Fetch images from directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\n\ndef get_num_pixels(filepath):\n    width, height = Image.open(filepath).size\n    return width*height\n\nprint get_num_pixels(\"../input/plantdisease/plantvillage/PlantVillage/Pepperbell___Bacterial_spot/0022d6b7-d47c-4ee2-ae9a-392a53f48647___JR_B.Spot8964.JPG\")","execution_count":4,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-4-cefe162923f1>, line 7)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-cefe162923f1>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print get_num_pixels(\"../input/plantdisease/plantvillage/PlantVillage/Pepper__bell___Bacterial_spot/0022d6b7-d47c-4ee2-ae9a-392a53f48647___JR_B.Spot8964.JPG\")\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#base_model=ResNet50(weights='imagenet',include_top=False,input_shape=(224, 224, 3)) \nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\nx=Dropout(rate=0.2)(x)\nx=Dense(512,activation='relu')(x) #dense layer 3\nx=Dropout(rate=0.2)(x)\npreds=Dense(15,activation='softmax')(x) #final layer with softmax activation\nmodel=Model(inputs=base_model.input,outputs=preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in base_model.layers:\n  layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [EarlyStopping(monitor='val_loss', patience=4),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,horizontal_flip = True,\n                                                 fill_mode = \"nearest\",\n                                                 zoom_range = 0.3,\n                                                 width_shift_range = 0.3,\n                                                 height_shift_range=0.3,\n                                                 rotation_range=30, validation_split=0.2) #included in our dependencies\n\ntrain_generator=train_datagen.flow_from_directory('/kaggle/input/plantdisease/plantvillage/PlantVillage',\n                                                 target_size=(224,224),\n                                                 color_mode='rgb',\n                                                 batch_size=batch_size,                \n                                                 class_mode='categorical',\n                                                 subset='training',shuffle=True,\n                                                 seed=42\n                                                 )\nvalidation_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/plantdisease/plantvillage/PlantVillage', # same directory as training data\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=True,\n    seed=42) # set as validation data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(model.layers))\nprint(model.layers[174:])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adam = Adam(lr=0.0001)\nmodel.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n# Adam optimizer\n# loss function will be categorical cross entropy\n# evaluation metric will be accuracy\n\n#step_size_train=train_generator.n//train_generator.batch_size\nstep_size_train=train_generator.n//batch_size\nSTEP_SIZE_VALID=validation_generator.n//batch_size\nprint(train_generator.n)\nprint(train_generator.batch_size)\nprint(step_size_train)\nhistory = model.fit_generator(generator=train_generator,\n                   steps_per_epoch=step_size_train,\n                   validation_data=validation_generator,\n                   validation_steps=STEP_SIZE_VALID,\n                   epochs=20,\n                   callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53b13c03e4cea6dc2453a84e254b806ebeed2d99"},"cell_type":"markdown","source":"Model Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate_generator(generator=validation_generator,\nsteps=STEP_SIZE_VALID)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save model and architecture to single file\nmodel.save(\"model.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\ntest_generator.reset()\npred=model.predict_generator(test_generator,\nsteps=STEP_SIZE_TEST,\nverbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_class_indices=np.argmax(pred,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames=test_generator.filenames\nresults=pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\":predictions})\nresults.to_csv(\"results.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1495fea08b37e4d4293f975ba30e6c1fc7a85ed9"},"cell_type":"markdown","source":"Plot the train and val curve"},{"metadata":{"trusted":true,"_uuid":"0af5e0f23657a4effc2d21cf8e840e81f42ec8e7"},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ca1a4489bd624c69a13cd37c0c2306ac8de55c2"},"cell_type":"markdown","source":"Model Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history\nprint(history_dict.keys())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a1f759db8afe933e62fe4cf8332cb303bb11be8"},"cell_type":"markdown","source":"Save model using Pickle"},{"metadata":{"trusted":true,"_uuid":"5cdf06adf492d79ed28fbdc36e02ad7489c7b33e"},"cell_type":"code","source":"# save the model to disk\nprint(\"[INFO] Saving model...\")\npickle.dump(model,open('cnn_model.pkl', 'wb'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}