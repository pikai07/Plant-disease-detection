{"cells":[{"metadata":{"_uuid":"1020827e241ac87ffdf8e0f8762a6885bdc28fbc"},"cell_type":"markdown","source":"Import neccessary packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pickle\nimport cv2\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n#from keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.models import Model\nimport os\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.applications.vgg16 import VGG16\n# load the model\nfrom keras.applications.vgg16 import preprocess_input","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"7c3354a78e21a1a62ad0c4689d0ab3238fb760d4"},"cell_type":"code","source":"EPOCHS = 25\nINIT_LR = 1e-3\nBS = 32\ndefault_image_size = tuple((256, 256))\nimage_size = 0\ndirectory_root = '../input/plantvillage/'\nwidth=256\nheight=256\ndepth=3\nbatch_size=64\nnb_epochs=50\nprint(os.listdir(\"../input\"))","execution_count":2,"outputs":[{"output_type":"stream","text":"['plantdisease']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfile_count = sum(len(files) for _, _, files in os.walk('../input/plantdisease/'))\nprint(file_count)\n\ntotal_files = 0\ntotal_dirs = 0\nfor root, dirs, files in os.walk('../input/plantdisease/'):\n    total_files += len(files)\n    total_dirs += len(dirs)\nprint(total_files)\nprint(total_dirs)\n\nfor r, d, f in os.walk('../input/plantdisease/'):\n    for file in f:\n        if '.txt' in file:\n            files.append(os.path.join(r, file))\n\nfor f in files:\n    print(f)\n\n\nprint([x[0] for x in os.walk('../input/plantdisease/')])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24d42b87fad54a9556f78357ce673cc5152468c1"},"cell_type":"markdown","source":"Fetch images from directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"#base_model=ResNet50(weights='imagenet',include_top=False,input_shape=(224, 224, 3)) \nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))","execution_count":3,"outputs":[{"output_type":"stream","text":"Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\nx=Dropout(rate=0.2)(x)\nx=Dense(512,activation='relu')(x) #dense layer 3\nx=Dropout(rate=0.2)(x)\npreds=Dense(15,activation='softmax')(x) #final layer with softmax activation\nmodel=Model(inputs=base_model.input,outputs=preds)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in base_model.layers:\n  layer.trainable = False","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [EarlyStopping(monitor='val_loss', patience=4),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,horizontal_flip = True,\n                                                 fill_mode = \"nearest\",\n                                                 zoom_range = 0.3,\n                                                 width_shift_range = 0.3,\n                                                 height_shift_range=0.3,\n                                                 rotation_range=30, validation_split=0.2) #included in our dependencies\n\ntrain_generator=train_datagen.flow_from_directory('/kaggle/input/plantdisease/plantvillage/PlantVillage',\n                                                 target_size=(224,224),\n                                                 color_mode='rgb',\n                                                 batch_size=batch_size,                \n                                                 class_mode='categorical',\n                                                 subset='training',shuffle=True,\n                                                 seed=42\n                                                 )\nvalidation_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/plantdisease/plantvillage/PlantVillage', # same directory as training data\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=True,\n    seed=42) # set as validation data","execution_count":7,"outputs":[{"output_type":"stream","text":"Found 16516 images belonging to 15 classes.\nFound 4122 images belonging to 15 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(model.layers))\nprint(model.layers[174:])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adam = Adam(lr=0.0001)\nmodel.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n# Adam optimizer\n# loss function will be categorical cross entropy\n# evaluation metric will be accuracy\n\n#step_size_train=train_generator.n//train_generator.batch_size\nstep_size_train=train_generator.n//batch_size\nSTEP_SIZE_VALID=validation_generator.n//batch_size\nprint(train_generator.n)\nprint(train_generator.batch_size)\nprint(step_size_train)\nhistory = model.fit_generator(generator=train_generator,\n                   steps_per_epoch=step_size_train,\n                   validation_data=validation_generator,\n                   validation_steps=STEP_SIZE_VALID,\n                   epochs=20,\n                   callbacks=callbacks)","execution_count":8,"outputs":[{"output_type":"stream","text":"16516\n64\n258\nEpoch 1/20\n258/258 [==============================] - 270s 1s/step - loss: 1.5035 - accuracy: 0.5387 - val_loss: 0.8320 - val_accuracy: 0.7688\nEpoch 2/20\n258/258 [==============================] - 240s 931ms/step - loss: 0.7968 - accuracy: 0.7381 - val_loss: 0.8338 - val_accuracy: 0.8270\nEpoch 3/20\n258/258 [==============================] - 241s 936ms/step - loss: 0.6373 - accuracy: 0.7914 - val_loss: 0.3842 - val_accuracy: 0.8438\nEpoch 4/20\n258/258 [==============================] - 240s 930ms/step - loss: 0.5451 - accuracy: 0.8186 - val_loss: 0.4575 - val_accuracy: 0.8546\nEpoch 5/20\n258/258 [==============================] - 239s 927ms/step - loss: 0.5066 - accuracy: 0.8316 - val_loss: 0.2394 - val_accuracy: 0.8728\nEpoch 6/20\n258/258 [==============================] - 239s 928ms/step - loss: 0.4693 - accuracy: 0.8455 - val_loss: 0.4427 - val_accuracy: 0.8797\nEpoch 7/20\n258/258 [==============================] - 237s 920ms/step - loss: 0.4357 - accuracy: 0.8525 - val_loss: 0.2211 - val_accuracy: 0.8825\nEpoch 8/20\n258/258 [==============================] - 238s 923ms/step - loss: 0.3989 - accuracy: 0.8675 - val_loss: 0.5392 - val_accuracy: 0.8913\nEpoch 9/20\n258/258 [==============================] - 237s 918ms/step - loss: 0.3834 - accuracy: 0.8716 - val_loss: 0.1466 - val_accuracy: 0.8997\nEpoch 10/20\n258/258 [==============================] - 237s 919ms/step - loss: 0.3609 - accuracy: 0.8798 - val_loss: 0.4234 - val_accuracy: 0.9004\nEpoch 11/20\n258/258 [==============================] - 236s 916ms/step - loss: 0.3445 - accuracy: 0.8823 - val_loss: 0.2743 - val_accuracy: 0.8955\nEpoch 12/20\n258/258 [==============================] - 235s 910ms/step - loss: 0.3264 - accuracy: 0.8875 - val_loss: 0.3470 - val_accuracy: 0.8990\nEpoch 13/20\n258/258 [==============================] - 234s 906ms/step - loss: 0.3278 - accuracy: 0.8931 - val_loss: 0.2827 - val_accuracy: 0.8967\n","name":"stdout"}]},{"metadata":{"_uuid":"53b13c03e4cea6dc2453a84e254b806ebeed2d99"},"cell_type":"markdown","source":"Model Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate_generator(generator=validation_generator,\nsteps=STEP_SIZE_VALID)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\ntest_generator.reset()\npred=model.predict_generator(test_generator,\nsteps=STEP_SIZE_TEST,\nverbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_class_indices=np.argmax(pred,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames=test_generator.filenames\nresults=pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\":predictions})\nresults.to_csv(\"results.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1495fea08b37e4d4293f975ba30e6c1fc7a85ed9"},"cell_type":"markdown","source":"Plot the train and val curve"},{"metadata":{"trusted":true,"_uuid":"0af5e0f23657a4effc2d21cf8e840e81f42ec8e7"},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ca1a4489bd624c69a13cd37c0c2306ac8de55c2"},"cell_type":"markdown","source":"Model Accuracy"},{"metadata":{"_uuid":"2a1f759db8afe933e62fe4cf8332cb303bb11be8"},"cell_type":"markdown","source":"Save model using Pickle"},{"metadata":{"trusted":true,"_uuid":"5cdf06adf492d79ed28fbdc36e02ad7489c7b33e"},"cell_type":"code","source":"# save the model to disk\nprint(\"[INFO] Saving model...\")\npickle.dump(model,open('cnn_model.pkl', 'wb'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}